{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bad4def2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9a375a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a404bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data_with_encoded_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6b5f32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sbert_encoded</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>vectors_processed_text</th>\n",
       "      <th>result_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Are you a fan of Google or Microsoft?</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "      <td>[-0.0944194421172142, -0.06091456487774849, 0....</td>\n",
       "      <td>['fan', 'google', 'microsoft']</td>\n",
       "      <td>[-0.2577203   0.01673527  0.11043102 -0.007317...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Both are excellent technology they are helpfu...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "      <td>[-0.08879820257425308, 0.014598547481000423, -...</td>\n",
       "      <td>['excellent', 'technology', 'helpful', 'many',...</td>\n",
       "      <td>[ 7.78763145e-02 -1.16512872e-01  9.14842412e-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm not  a huge fan of Google, but I use it a...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "      <td>[-0.12374246120452881, -0.13280555605888367, 0...</td>\n",
       "      <td>['huge', 'fan', 'google', 'use', 'lot', 'think...</td>\n",
       "      <td>[ 0.0691651   0.09834016  0.00798483 -0.014965...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Google provides online related services and p...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "      <td>[-0.0931607335805893, -0.06753479689359665, 0....</td>\n",
       "      <td>['google', 'provides', 'online', 'related', 's...</td>\n",
       "      <td>[-0.08403432 -0.02970078 -0.10023852 -0.097848...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Yeah, their services are good. I'm just not a...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "      <td>[-0.059885457158088684, -0.06240694224834442, ...</td>\n",
       "      <td>['yeah', 'service', 'good', 'fan', 'intrusive'...</td>\n",
       "      <td>[-2.31601238e-01  7.56546855e-02  1.46629840e-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  conversation_id  \\\n",
       "0             0           0                1   \n",
       "1             1           1                1   \n",
       "2             2           2                1   \n",
       "3             3           3                1   \n",
       "4             4           4                1   \n",
       "\n",
       "                                             message                sentiment  \\\n",
       "0              Are you a fan of Google or Microsoft?   Curious to dive deeper   \n",
       "1   Both are excellent technology they are helpfu...   Curious to dive deeper   \n",
       "2   I'm not  a huge fan of Google, but I use it a...   Curious to dive deeper   \n",
       "3   Google provides online related services and p...   Curious to dive deeper   \n",
       "4   Yeah, their services are good. I'm just not a...   Curious to dive deeper   \n",
       "\n",
       "                                       sbert_encoded  \\\n",
       "0  [-0.0944194421172142, -0.06091456487774849, 0....   \n",
       "1  [-0.08879820257425308, 0.014598547481000423, -...   \n",
       "2  [-0.12374246120452881, -0.13280555605888367, 0...   \n",
       "3  [-0.0931607335805893, -0.06753479689359665, 0....   \n",
       "4  [-0.059885457158088684, -0.06240694224834442, ...   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0                     ['fan', 'google', 'microsoft']   \n",
       "1  ['excellent', 'technology', 'helpful', 'many',...   \n",
       "2  ['huge', 'fan', 'google', 'use', 'lot', 'think...   \n",
       "3  ['google', 'provides', 'online', 'related', 's...   \n",
       "4  ['yeah', 'service', 'good', 'fan', 'intrusive'...   \n",
       "\n",
       "                              vectors_processed_text  result_Encoded  \n",
       "0  [-0.2577203   0.01673527  0.11043102 -0.007317...               1  \n",
       "1  [ 7.78763145e-02 -1.16512872e-01  9.14842412e-...               1  \n",
       "2  [ 0.0691651   0.09834016  0.00798483 -0.014965...               1  \n",
       "3  [-0.08403432 -0.02970078 -0.10023852 -0.097848...               1  \n",
       "4  [-2.31601238e-01  7.56546855e-02  1.46629840e-...               1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "973dd333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>vectors_processed_text</th>\n",
       "      <th>result_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Are you a fan of Google or Microsoft?</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "      <td>['fan', 'google', 'microsoft']</td>\n",
       "      <td>[-0.2577203   0.01673527  0.11043102 -0.007317...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Both are excellent technology they are helpfu...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "      <td>['excellent', 'technology', 'helpful', 'many',...</td>\n",
       "      <td>[ 7.78763145e-02 -1.16512872e-01  9.14842412e-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm not  a huge fan of Google, but I use it a...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "      <td>['huge', 'fan', 'google', 'use', 'lot', 'think...</td>\n",
       "      <td>[ 0.0691651   0.09834016  0.00798483 -0.014965...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Google provides online related services and p...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "      <td>['google', 'provides', 'online', 'related', 's...</td>\n",
       "      <td>[-0.08403432 -0.02970078 -0.10023852 -0.097848...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Yeah, their services are good. I'm just not a...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "      <td>['yeah', 'service', 'good', 'fan', 'intrusive'...</td>\n",
       "      <td>[-2.31601238e-01  7.56546855e-02  1.46629840e-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188373</th>\n",
       "      <td>188373</td>\n",
       "      <td>188373</td>\n",
       "      <td>8628</td>\n",
       "      <td>Wow, it does not seem like that long. Since I...</td>\n",
       "      <td>Surprised</td>\n",
       "      <td>['wow', 'seem', 'like', 'long', 'since', 'ment...</td>\n",
       "      <td>[-2.25231964e-02  4.94860150e-02  3.60752270e-...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188374</th>\n",
       "      <td>188374</td>\n",
       "      <td>188374</td>\n",
       "      <td>8628</td>\n",
       "      <td>I havent seen that episode, I might google it...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "      <td>['havent', 'seen', 'episode', 'might', 'google...</td>\n",
       "      <td>[ 3.50610614e-02 -1.43267913e-02  1.25734389e-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188375</th>\n",
       "      <td>188375</td>\n",
       "      <td>188375</td>\n",
       "      <td>8628</td>\n",
       "      <td>I don't think I have either. That's an insane...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "      <td>['think', 'either', 'insane', 'amount', 'episo...</td>\n",
       "      <td>[-1.31636903e-01 -1.58960387e-01  5.85873723e-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188376</th>\n",
       "      <td>188376</td>\n",
       "      <td>188376</td>\n",
       "      <td>8628</td>\n",
       "      <td>I did, my little brother used to love Thomas ...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>['little', 'brother', 'used', 'love', 'thomas'...</td>\n",
       "      <td>[-1.78009808e-01 -2.69305944e-01  2.69410521e-...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188377</th>\n",
       "      <td>188377</td>\n",
       "      <td>188377</td>\n",
       "      <td>8628</td>\n",
       "      <td>It did. Ringo Starr, George Carlin, and Alec ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>['ringo', 'starr', 'george', 'carlin', 'alec',...</td>\n",
       "      <td>[-6.60682321e-01 -5.94650388e-01 -2.37850577e-...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188378 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0.1  Unnamed: 0  conversation_id  \\\n",
       "0                  0           0                1   \n",
       "1                  1           1                1   \n",
       "2                  2           2                1   \n",
       "3                  3           3                1   \n",
       "4                  4           4                1   \n",
       "...              ...         ...              ...   \n",
       "188373        188373      188373             8628   \n",
       "188374        188374      188374             8628   \n",
       "188375        188375      188375             8628   \n",
       "188376        188376      188376             8628   \n",
       "188377        188377      188377             8628   \n",
       "\n",
       "                                                  message  \\\n",
       "0                   Are you a fan of Google or Microsoft?   \n",
       "1        Both are excellent technology they are helpfu...   \n",
       "2        I'm not  a huge fan of Google, but I use it a...   \n",
       "3        Google provides online related services and p...   \n",
       "4        Yeah, their services are good. I'm just not a...   \n",
       "...                                                   ...   \n",
       "188373   Wow, it does not seem like that long. Since I...   \n",
       "188374   I havent seen that episode, I might google it...   \n",
       "188375   I don't think I have either. That's an insane...   \n",
       "188376   I did, my little brother used to love Thomas ...   \n",
       "188377   It did. Ringo Starr, George Carlin, and Alec ...   \n",
       "\n",
       "                      sentiment  \\\n",
       "0        Curious to dive deeper   \n",
       "1        Curious to dive deeper   \n",
       "2        Curious to dive deeper   \n",
       "3        Curious to dive deeper   \n",
       "4        Curious to dive deeper   \n",
       "...                         ...   \n",
       "188373                Surprised   \n",
       "188374   Curious to dive deeper   \n",
       "188375   Curious to dive deeper   \n",
       "188376                    Happy   \n",
       "188377                  Neutral   \n",
       "\n",
       "                                           processed_text  \\\n",
       "0                          ['fan', 'google', 'microsoft']   \n",
       "1       ['excellent', 'technology', 'helpful', 'many',...   \n",
       "2       ['huge', 'fan', 'google', 'use', 'lot', 'think...   \n",
       "3       ['google', 'provides', 'online', 'related', 's...   \n",
       "4       ['yeah', 'service', 'good', 'fan', 'intrusive'...   \n",
       "...                                                   ...   \n",
       "188373  ['wow', 'seem', 'like', 'long', 'since', 'ment...   \n",
       "188374  ['havent', 'seen', 'episode', 'might', 'google...   \n",
       "188375  ['think', 'either', 'insane', 'amount', 'episo...   \n",
       "188376  ['little', 'brother', 'used', 'love', 'thomas'...   \n",
       "188377  ['ringo', 'starr', 'george', 'carlin', 'alec',...   \n",
       "\n",
       "                                   vectors_processed_text  result_Encoded  \n",
       "0       [-0.2577203   0.01673527  0.11043102 -0.007317...               1  \n",
       "1       [ 7.78763145e-02 -1.16512872e-01  9.14842412e-...               1  \n",
       "2       [ 0.0691651   0.09834016  0.00798483 -0.014965...               1  \n",
       "3       [-0.08403432 -0.02970078 -0.10023852 -0.097848...               1  \n",
       "4       [-2.31601238e-01  7.56546855e-02  1.46629840e-...               1  \n",
       "...                                                   ...             ...  \n",
       "188373  [-2.25231964e-02  4.94860150e-02  3.60752270e-...               7  \n",
       "188374  [ 3.50610614e-02 -1.43267913e-02  1.25734389e-...               1  \n",
       "188375  [-1.31636903e-01 -1.58960387e-01  5.85873723e-...               1  \n",
       "188376  [-1.78009808e-01 -2.69305944e-01  2.69410521e-...               4  \n",
       "188377  [-6.60682321e-01 -5.94650388e-01 -2.37850577e-...               5  \n",
       "\n",
       "[188378 rows x 8 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['sbert_encoded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d20d7a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['vectors_processed_text']\n",
    "# X = df['sbert_encoded']\n",
    "Y = df['result_Encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0867ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert string vectors (NumPy array format) to numeric arrays\n",
    "def parse_vector(vec_str):\n",
    "    if isinstance(vec_str, str):\n",
    "        # Remove brackets and replace commas with spaces\n",
    "        cleaned = vec_str.replace(\",\", \" \").strip(\"[]\").split()\n",
    "        return np.array([float(x) for x in cleaned if x])\n",
    "    return np.array(vec_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80f5a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_resampled = np.array([parse_vector(v) for v in df['sbert_encoded']])\n",
    "X_resampled = np.array([parse_vector(v) for v in df['vectors_processed_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5627023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91fee3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68405d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new, y_new = smote.fit_resample(X_scaled, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3785d43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result_Encoded\n",
       "1    80888\n",
       "4    80888\n",
       "5    80888\n",
       "7    80888\n",
       "2    80888\n",
       "6    80888\n",
       "3    80888\n",
       "0    80888\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "99a61132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (32000, 2)\n",
      "Final class distribution:\n",
      "result_Encoded\n",
      "0    4000\n",
      "1    4000\n",
      "2    4000\n",
      "3    4000\n",
      "4    4000\n",
      "5    4000\n",
      "6    4000\n",
      "7    4000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame from SMOTE resampled data\n",
    "df_resampled = pd.DataFrame({\n",
    "    \"vectors\": [vec for vec in X_new],\n",
    "    \"result_Encoded\": y_new\n",
    "})\n",
    "\n",
    "# Keep only 4k rows per class\n",
    "new_df = df_resampled.groupby(\"result_Encoded\").sample(n=4000, random_state=42).reset_index(drop=True)\n",
    "print(f\"Final shape: {new_df.shape}\")\n",
    "print(\"Final class distribution:\")\n",
    "print(new_df[\"result_Encoded\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31b04cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('../data/vectors_and_result_only_word2vec.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acd3bdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.read_csv('../data/vectors_and_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a7d3724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db76c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
